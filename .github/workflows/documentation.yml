name: documentation
concurrency:
  group: ${{ github.workflow }}-${{ github.event.number }}-${{ github.event.ref }}
  cancel-in-progress: true

on: [push, pull_request, workflow_dispatch]

permissions:
  contents: write

jobs:
  docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2
        with:
          fetch-depth: 0
          persist-credentials: false
      - uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38  # v5.4.0
        with:
          python-version: "3.10"
      - uses: nickg/setup-nvc-ci@40dcbd31cf07b60479a31f94a5df70c0bfbb9ce5  # v1v1
        with:
          version: latest
      - name: Check simulator installation
        run: |
          nvc --version # Make sure nvc was installed successfully
      - name: Install dependencies
        run: |
          sudo apt-get install -yy doxygen
          python -m pip install --upgrade pip
          python -m pip install -v .[docs,comparison,benchmark]
      - name: Run comparisons
        run: |
          cd comparison
          python comparison.py
          cd ..
          mkdir -p docs/_static/
          cp comparison/comparison*.png docs/_static
      - name: Generate plots
        run: |
          cd docs
          python _plots/quantization.py
          python _plots/performancescale.py
          python _plots/overflow.py
          cp *.png _static
          cd ..
      # Remove all instances of APY_INLINE, except the define itself,
      # as it breaks doc generation
      - name: Remove APY_INLINE
        run: |
          sed -i "s/static APY_INLINE/static inline/g" src/*.h src/*.cc
          sed -i "s/    APY_INLINE/    inline/g" src/*.h src/*.cc
          sed -i "s/^APY_INLINE/inline/g" src/*.h src/*.cc
      - name: Sphinx build
        run: |
          cd docs
          make html
          cd ..
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@4f9cc6602d3f66b9c108549d475ec49e8ef4d45e  # v4.0.0
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          publish_branch: gh-pages
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: docs/_build/html
          keep_files: true
      # Checkout previous version so that doc-files can be written
      - name: Restore APY_INLINE
        run: |
          git checkout -- src/apybuffer.h src/apyfloat.h src/apyfixed.h src/apytypes_common.h src/apytypes_util.h src/ieee754.h src/python_util.h src/apyfloatarray.h src/apyfixedarray.h src/apyfloat_util.h src/broadcast.h src/array_utils.h src/apyfixed_util.h src/apycfixed.h src/apycfixedarray.h src/apycfloat.h src/apycfloatarray.h
      # Download previous benchmark result from cache (if exists)
      - name: Download previous benchmark data
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57  # v4.2.0
        with:
          path: ./cache
          key: ${{ runner.os }}-benchmark
      - name: Run fixed array benchmark
        run: cd benchmark && pytest ci_fixed_array_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_fixed_array.json
        # Run `github-action-benchmark` action
      - name: Store fixed array benchmark result
        uses: benchmark-action/github-action-benchmark@d48d326b4ca9ba73ca0cd0d59f108f9e02a381c7  # v1.20.4
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Fixed-Point Array Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_fixed_array.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_fixed_array.json cache/
      - name: Run float array benchmark
        run: cd benchmark && pytest ci_float_array_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_float_array.json
        # Run `github-action-benchmark` action
      - name: Store float array benchmark result
        uses: benchmark-action/github-action-benchmark@d48d326b4ca9ba73ca0cd0d59f108f9e02a381c7  # v1.20.4
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Floating-Point Array Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_float_array.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_float_array.json cache/
      - name: Run fixed scalar benchmark
        run: cd benchmark && pytest ci_fixed_scalar_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_fixed_scalar.json
        # Run `github-action-benchmark` action
      - name: Store fixed scalar benchmark result
        uses: benchmark-action/github-action-benchmark@d48d326b4ca9ba73ca0cd0d59f108f9e02a381c7  # v1.20.4
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Fixed-Point Scalar Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_fixed_scalar.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_fixed_scalar.json cache/
      - name: Run float scalar benchmark
        run: cd benchmark && pytest ci_float_scalar_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_float_scalar.json
        # Run `github-action-benchmark` action
      - name: Store float scalar benchmark result
        uses: benchmark-action/github-action-benchmark@d48d326b4ca9ba73ca0cd0d59f108f9e02a381c7  # v1.20.4
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Floating-Point Scalar Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_float_scalar.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_float_scalar.json cache/
