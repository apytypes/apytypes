name: documentation

on: [push, pull_request, workflow_dispatch]

permissions:
  contents: write

jobs:
  docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: |
          sudo apt-get install -yy doxygen
          python -m pip install --upgrade pip
          python -m pip install -v .[docs,comparison,benchmark]
      - name: Run comparisons
        run: |
          cd comparison
          python comparison.py
          cd ..
          mkdir -p docs/_static/
          cp comparison/comparison*.png docs/_static
      - name: Generate plots
        run: |
          cd docs/_plots
          python quantization.py
          cp *.png ../_static
          cd ..
          cd ..
      - name: Sphinx build
        run: |
          cd docs
          make html
          cd ..
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          publish_branch: gh-pages
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: docs/_build/html
          keep_files: true
      # Download previous benchmark result from cache (if exists)
      - name: Download previous benchmark data
        uses: actions/cache@v4
        with:
          path: ./cache
          key: ${{ runner.os }}-benchmark
      - name: Run fixed array benchmark
        run: cd benchmark && pytest ci_fixed_array_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_fixed_array.json
        # Run `github-action-benchmark` action
      - name: Store fixed array benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Fixed-Point Array Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_fixed_array.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_fixed_array.json cache/
      - name: Run float array benchmark
        run: cd benchmark && pytest ci_float_array_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_float_array.json
        # Run `github-action-benchmark` action
      - name: Store float array benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Floating-Point Array Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_float_array.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_float_array.json cache/
      - name: Run fixed scalar benchmark
        run: cd benchmark && pytest ci_fixed_scalar_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_fixed_scalar.json
        # Run `github-action-benchmark` action
      - name: Store fixed scalar benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Fixed-Point Scalar Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_fixed_scalar.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_fixed_scalar.json cache/
      - name: Run float scalar benchmark
        run: cd benchmark && pytest ci_float_scalar_benchmarks.py --benchmark-warmup=on --benchmark-warmup-iterations=1 --benchmark-json output_float_scalar.json
        # Run `github-action-benchmark` action
      - name: Store float scalar benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        with:
          name: APyTypes Floating-Point Scalar Benchmarks
          # What benchmark tool the output.txt came from
          tool: 'pytest'
          # Where the output from the benchmark tool is stored
          output-file-path: benchmark/output_float_scalar.json
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
      - name: Copy previous file to cache
        run: mkdir -p cache && cp benchmark/output_float_scalar.json cache/
